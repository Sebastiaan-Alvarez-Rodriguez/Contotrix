# Current ideas
 1. DONE - Get code of parsers to work
 2. DONE - Use python framework to run code using subprocesses
 3. DONE - Use psutil.memory_percent() for avg mem usage and psutil.cpu_percent() for avg cpu usage . See [here](https://psutil.readthedocs.io/en/latest/)

# Currently working
In C:
 1. Haut
 2. Gumbo
 3. Lexbor
 4. Tooska (but gives errors/warnings for no reason)
In Python:
 1. html.parser (pyTHMLParser)
 2. beautifulsoup (pyBeautifulSoup)
 3. lxml (pylxml)
In Java:
TODO: Get Java parsers

# Datasets
 Some large ones:
 1. [Websites reffering to wikipedia](https://code.google.com/archive/p/wiki-links/downloads)
 2. [Mine for more datasets](https://www.researchgate.net/post/Where_can_I_find_the_web_pages_dataset_for_information_extraction)
 3. Go collecting myself? I could take from multiple sources, storing by doing md5/sha2 to prevent collisions

## HTML parsers for Python
[here](https://stackoverflow.com/questions/11709079/parsing-html-using-python)